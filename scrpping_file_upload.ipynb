{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# comma seperated values\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def process_cpt_code(driver, cpt_code):\n",
    "    wait = WebDriverWait(driver, 20)  # Increased timeout\n",
    "    results = []  # Initialize the results list\n",
    "\n",
    "    # Enter the CPT code into the search box\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        search_box = wait.until(EC.presence_of_element_located((By.ID, 'tbxSearchBox')))\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(cpt_code)\n",
    "    except TimeoutException:\n",
    "        print(f\"Search box not found for CPT code: {cpt_code}\")\n",
    "        results.append({'cpt_code': cpt_code, 'article_id': '', 'keyword': '', 'similar_paragraphs': ''})  # Add CPT code with no article ID\n",
    "        return results\n",
    "    \n",
    "    # Click the search button\n",
    "    submit_button = driver.find_element(By.ID, 'btnSubmitSearch')\n",
    "    submit_button.click()\n",
    "    print(f\"Submitted CPT code: {cpt_code}\")\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "    # Wait for the search results to load\n",
    "    try:\n",
    "        wait.until(EC.visibility_of_element_located((By.ID, 'searchResultsDiv')))\n",
    "        print(\"Search results loaded successfully.\")\n",
    "    except TimeoutException:\n",
    "        print(f\"Search results not loaded for CPT code: {cpt_code}\")\n",
    "        results.append({'cpt_code': cpt_code, 'article_id': '', 'keyword': '', 'similar_paragraphs': ''})  # Add CPT code with no article ID\n",
    "        return results\n",
    "\n",
    "    # Get the total number of results\n",
    "    try:\n",
    "        total_results_element = driver.find_element(By.ID, 'lblTotalResults')\n",
    "        total_results = int(total_results_element.text)\n",
    "        print(f\"Total results for CPT code {cpt_code}: {total_results}\")\n",
    "    except ValueError:\n",
    "        print(f\"Invalid total results value for CPT code: {cpt_code}\")\n",
    "        results.append({'cpt_code': cpt_code, 'article_id': '', 'keyword': '', 'similar_paragraphs': ''})  # Add CPT code with no article ID\n",
    "        return results\n",
    "\n",
    "    # Flag to track if we have processed all articles\n",
    "    processed_all_articles = False\n",
    "\n",
    "    # Keywords to search within the article\n",
    "    keywords = ['denied', 'non-covered', 'not covered', 'noncovered']\n",
    "\n",
    "    # Initialize dictionaries to hold aggregated results\n",
    "    article_ids = []\n",
    "    keywords_found = []\n",
    "    similar_paragraphs = []\n",
    "\n",
    "    # Iterate through each result\n",
    "    for i in range(total_results):\n",
    "        if processed_all_articles:\n",
    "            break  # If all articles are processed, exit the loop\n",
    "        \n",
    "        print(f\"Processing article {i + 1} of {total_results} for CPT code: {cpt_code}\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Re-fetch article elements after each iteration\n",
    "        article_elements = driver.find_elements(By.CLASS_NAME, 'table-title-col')\n",
    "        if i < len(article_elements):\n",
    "            try:\n",
    "                # Scroll the article element into view to ensure it's clickable\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", article_elements[i])\n",
    "                time.sleep(1)  # Allow some time for the page to settle\n",
    "                \n",
    "                # Try clicking the article using JavaScript to avoid interception\n",
    "                driver.execute_script(\"arguments[0].click();\", article_elements[i])\n",
    "                time.sleep(1)  # Allow time for the article to load\n",
    "\n",
    "                # Handle initial pop-ups (e.g., accept cookies)\n",
    "                try:\n",
    "                    accept_button = wait.until(EC.element_to_be_clickable((By.ID, 'btnAcceptLicense')))\n",
    "                    accept_button.click()\n",
    "                except TimeoutException:\n",
    "                    pass\n",
    "\n",
    "                # Wait for the article content to load and extract paragraphs\n",
    "                wait.until(EC.presence_of_element_located((By.ID, 'h3ArticleGuidanceHeader')))\n",
    "                \n",
    "                # Use BeautifulSoup to parse the article page\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                paragraphs = soup.find_all('p')  # Extract all paragraphs\n",
    "                \n",
    "                # Track whether any keywords were found in the article\n",
    "                article_keywords = []\n",
    "                article_paragraphs = []\n",
    "                for paragraph in paragraphs:\n",
    "                    for keyword in keywords:\n",
    "                        if re.search(r'\\b{}\\b'.format(re.escape(keyword)), paragraph.get_text(), re.IGNORECASE):\n",
    "                            article_keywords.append(keyword)\n",
    "                            article_paragraphs.append(paragraph.get_text())\n",
    "                            break  # Stop after finding the first matching keyword in a paragraph\n",
    "\n",
    "                if article_keywords:\n",
    "                    article_id = driver.find_element(By.ID, 'lblTitleId').text\n",
    "                    article_ids.append(article_id)\n",
    "                    keywords_found.extend(article_keywords)\n",
    "                    similar_paragraphs.extend(article_paragraphs)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing article {i + 1}: {e}\")\n",
    "\n",
    "            finally:\n",
    "                # After processing each article, check if all results are processed\n",
    "                if i + 1 == total_results:\n",
    "                    processed_all_articles = True  # We have processed all articles\n",
    "                else:\n",
    "                    # Return to search results page if not the last article\n",
    "                    driver.back()\n",
    "                    print(f\"Returned to search results for CPT code: {cpt_code}\")\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "                    # Explicit wait to ensure the page reloads\n",
    "                    wait.until(EC.visibility_of_element_located((By.ID, 'searchResultsDiv')))\n",
    "                    time.sleep(1)\n",
    "        else:\n",
    "            print(f\"No article element found for index {i}. Skipping.\")\n",
    "\n",
    "    # Aggregate results into single row for the CPT code\n",
    "    if article_ids:\n",
    "        results.append({\n",
    "            'cpt_code': cpt_code, \n",
    "            'article_id': ', '.join(article_ids), \n",
    "            'keyword': ', '.join(keywords_found), \n",
    "            'similar_paragraphs': '\\n\\n'.join(similar_paragraphs)\n",
    "        })\n",
    "    else:\n",
    "        results.append({'cpt_code': cpt_code, 'article_id': '', 'keyword': '', 'similar_paragraphs': ''})\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_file = 'input.xlsx'\n",
    "    output_file = 'output.xlsx'\n",
    "\n",
    "    # Load the input Excel file\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # Ensure the CPT_CODE column is treated as a string\n",
    "    df['CPT_CODE'] = df['CPT_CODE'].astype(str).apply(lambda x: x.zfill(5))\n",
    "\n",
    "    # Setup Selenium WebDriver\n",
    "    driver = webdriver.Chrome()  # Adjust the driver if needed (e.g., Edge, Firefox)\n",
    "\n",
    "    # Process each CPT code\n",
    "    all_results = []\n",
    "    for _, row in df.iterrows():\n",
    "        cpt_code = row['CPT_CODE']\n",
    "        driver.get('abc.com')\n",
    "        results = process_cpt_code(driver, cpt_code)\n",
    "        if results:  # Check if results are not empty\n",
    "            all_results.extend(results)\n",
    "\n",
    "    # Save results to a new Excel file\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df.to_excel(output_file, index=False)\n",
    "    print(\"Results written to Excel successfully!\")\n",
    "\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "    print(\"Process completed successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single line comments\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def process_cpt_code(driver, cpt_code):\n",
    "    wait = WebDriverWait(driver, 20)  # Increased timeout\n",
    "    results = []  # Initialize the results list\n",
    "\n",
    "    # Enter the CPT code into the search box\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        search_box = wait.until(EC.presence_of_element_located((By.ID, 'tbxSearchBox')))\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(cpt_code)\n",
    "    except TimeoutException:\n",
    "        print(f\"Search box not found for CPT code: {cpt_code}\")\n",
    "        results.append({'cpt_code': cpt_code, 'article_id': '', 'keyword': '', 'similar_paragraphs': ''})  # Add CPT code with no article ID\n",
    "        return results\n",
    "    \n",
    "    # Click the search button\n",
    "    submit_button = driver.find_element(By.ID, 'btnSubmitSearch')\n",
    "    submit_button.click()\n",
    "    print(f\"Submitted CPT code: {cpt_code}\")\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "    # Wait for the search results to load\n",
    "    try:\n",
    "        wait.until(EC.visibility_of_element_located((By.ID, 'searchResultsDiv')))\n",
    "        print(\"Search results loaded successfully.\")\n",
    "    except TimeoutException:\n",
    "        print(f\"Search results not loaded for CPT code: {cpt_code}\")\n",
    "        results.append({'cpt_code': cpt_code, 'article_id': '', 'keyword': '', 'similar_paragraphs': ''})  # Add CPT code with no article ID\n",
    "        return results\n",
    "\n",
    "    # Get the total number of results\n",
    "    try:\n",
    "        total_results_element = driver.find_element(By.ID, 'lblTotalResults')\n",
    "        total_results = int(total_results_element.text)\n",
    "        print(f\"Total results for CPT code {cpt_code}: {total_results}\")\n",
    "    except ValueError:\n",
    "        print(f\"Invalid total results value for CPT code: {cpt_code}\")\n",
    "        results.append({'cpt_code': cpt_code, 'article_id': '', 'keyword': '', 'similar_paragraphs': ''})  # Add CPT code with no article ID\n",
    "        return results\n",
    "\n",
    "    # Flag to track if we have processed all articles\n",
    "    processed_all_articles = False\n",
    "\n",
    "    # Keywords to search within the article\n",
    "    keywords = ['denied', 'non-covered', 'not covered', 'noncovered']\n",
    "\n",
    "    # Iterate through each result\n",
    "    for i in range(total_results):\n",
    "        if processed_all_articles:\n",
    "            break  # If all articles are processed, exit the loop\n",
    "        \n",
    "        print(f\"Processing article {i + 1} of {total_results} for CPT code: {cpt_code}\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Re-fetch article elements after each iteration\n",
    "        article_elements = driver.find_elements(By.CLASS_NAME, 'table-title-col')\n",
    "        if i < len(article_elements):\n",
    "            try:\n",
    "                # Scroll the article element into view to ensure it's clickable\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", article_elements[i])\n",
    "                time.sleep(1)  # Allow some time for the page to settle\n",
    "                \n",
    "                # Try clicking the article using JavaScript to avoid interception\n",
    "                driver.execute_script(\"arguments[0].click();\", article_elements[i])\n",
    "                time.sleep(1)  # Allow time for the article to load\n",
    "\n",
    "                # Handle initial pop-ups (e.g., accept cookies)\n",
    "                try:\n",
    "                    accept_button = wait.until(EC.element_to_be_clickable((By.ID, 'btnAcceptLicense')))\n",
    "                    accept_button.click()\n",
    "                except TimeoutException:\n",
    "                    pass\n",
    "\n",
    "                # Wait for the article content to load and extract paragraphs\n",
    "                wait.until(EC.presence_of_element_located((By.ID, 'h3ArticleGuidanceHeader')))\n",
    "                \n",
    "                # Use BeautifulSoup to parse the article page\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                paragraphs = soup.find_all('p')  # Extract all paragraphs\n",
    "                \n",
    "                similar_paragraphs = []\n",
    "                for paragraph in paragraphs:\n",
    "                    for keyword in keywords:\n",
    "                        if re.search(r'\\b{}\\b'.format(re.escape(keyword)), paragraph.get_text(), re.IGNORECASE):\n",
    "                            similar_paragraphs.append(paragraph.get_text())\n",
    "                            # Store the keyword that matched\n",
    "                            results.append({\n",
    "                                'cpt_code': cpt_code, \n",
    "                                'article_id': driver.find_element(By.ID, 'lblTitleId').text, \n",
    "                                'keyword': keyword, \n",
    "                                'similar_paragraphs': paragraph.get_text()\n",
    "                            })\n",
    "                            break  # Stop after finding the first matching keyword in a paragraph\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing article {i + 1}: {e}\")\n",
    "\n",
    "            finally:\n",
    "                # After processing each article, check if all results are processed\n",
    "                if i + 1 == total_results:\n",
    "                    processed_all_articles = True  # We have processed all articles\n",
    "                else:\n",
    "                    # Return to search results page if not the last article\n",
    "                    driver.back()\n",
    "                    print(f\"Returned to search results for CPT code: {cpt_code}\")\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "                    # Explicit wait to ensure the page reloads\n",
    "                    wait.until(EC.visibility_of_element_located((By.ID, 'searchResultsDiv')))\n",
    "                    time.sleep(1)\n",
    "        else:\n",
    "            print(f\"No article element found for index {i}. Skipping.\")\n",
    "\n",
    "    # If no articles are found for this CPT code, ensure it gets added with an empty article ID\n",
    "    if not results:\n",
    "        results.append({'cpt_code': cpt_code, 'article_id': '', 'keyword': '', 'similar_paragraphs': ''})\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_file = 'input.xlsx'\n",
    "    output_file = 'output.xlsx'\n",
    "\n",
    "    # Load the input Excel file\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # Ensure the CPT_CODE column is treated as a string\n",
    "    df['CPT_CODE'] = df['CPT_CODE'].astype(str)\n",
    "\n",
    "    # Setup Selenium WebDriver\n",
    "    driver = webdriver.Chrome()  # Adjust the driver if needed (e.g., Edge, Firefox)\n",
    "\n",
    "    # Process each CPT code\n",
    "    all_results = []\n",
    "    for _, row in df.iterrows():\n",
    "        cpt_code = row['CPT_CODE']\n",
    "        driver.get('https://www.cms.gov/medicare-coverage-database/search.aspx')\n",
    "        results = process_cpt_code(driver, cpt_code)\n",
    "        if results:  # Check if results are not empty\n",
    "            all_results.extend(results)\n",
    "\n",
    "    # Save results to a new Excel file\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df.to_excel(output_file, index=False)\n",
    "    print(\"Results written to Excel successfully!\")\n",
    "\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "    print(\"Process completed successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
